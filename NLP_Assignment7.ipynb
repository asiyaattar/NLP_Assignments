{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApovDvIWMRCw",
        "outputId": "85b200d3-386e-47ff-9af3-f7abb9209b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced N-Gram Auto-Complete System\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "# ----------------------------\n",
        "# Text Preprocessing\n",
        "# ----------------------------\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Build N-gram Model\n",
        "# ----------------------------\n",
        "\n",
        "class NGramAutoComplete:\n",
        "\n",
        "    def __init__(self, corpus, n=3):\n",
        "        self.n = n\n",
        "        self.tokens = preprocess(corpus)\n",
        "\n",
        "        self.unigrams = Counter()\n",
        "        self.bigrams = defaultdict(Counter)\n",
        "        self.trigrams = defaultdict(Counter)\n",
        "\n",
        "        self.build_model()\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        tokens = self.tokens\n",
        "\n",
        "        # Unigrams\n",
        "        for word in tokens:\n",
        "            self.unigrams[word] += 1\n",
        "\n",
        "        # Bigrams\n",
        "        for i in range(len(tokens)-1):\n",
        "            self.bigrams[tokens[i]][tokens[i+1]] += 1\n",
        "\n",
        "        # Trigrams\n",
        "        for i in range(len(tokens)-2):\n",
        "            key = (tokens[i], tokens[i+1])\n",
        "            self.trigrams[key][tokens[i+2]] += 1\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Predict Next Word\n",
        "    # ----------------------------\n",
        "\n",
        "    def predict_next(self, text, top_k=5):\n",
        "\n",
        "        words = preprocess(text)\n",
        "\n",
        "        if len(words) >= 2:\n",
        "            w1, w2 = words[-2], words[-1]\n",
        "\n",
        "            if (w1, w2) in self.trigrams:\n",
        "                preds = self.trigrams[(w1, w2)]\n",
        "                return self.get_top(preds, top_k, \"Trigram\")\n",
        "\n",
        "\n",
        "        if len(words) >= 1:\n",
        "            w = words[-1]\n",
        "\n",
        "            if w in self.bigrams:\n",
        "                preds = self.bigrams[w]\n",
        "                return self.get_top(preds, top_k, \"Bigram\")\n",
        "\n",
        "\n",
        "        return self.get_top(self.unigrams, top_k, \"Unigram\")\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Get Top Predictions\n",
        "    # ----------------------------\n",
        "\n",
        "    def get_top(self, counter, k, model):\n",
        "\n",
        "        total = sum(counter.values())\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for word, count in counter.most_common(k):\n",
        "            prob = round(count / total, 4)\n",
        "            results.append((word, prob))\n",
        "\n",
        "        return model, results\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Sample Training Corpus\n",
        "# ----------------------------\n",
        "\n",
        "corpus = \"\"\"\n",
        "Natural language processing is a field of artificial intelligence.\n",
        "It focuses on the interaction between computers and human language.\n",
        "Language models are important in machine translation and speech recognition.\n",
        "Auto complete systems help users type faster.\n",
        "N gram models are widely used in NLP.\n",
        "Deep learning models improve language understanding.\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------------\n",
        "# Train Model\n",
        "# ----------------------------\n",
        "\n",
        "model = NGramAutoComplete(corpus)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Interactive Prediction\n",
        "# ----------------------------\n",
        "\n",
        "while True:\n",
        "\n",
        "    text = input(\"\\nEnter text (or 'exit'): \")\n",
        "\n",
        "    if text.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    level, predictions = model.predict_next(text)\n",
        "\n",
        "    print(f\"\\nUsing {level} Model\")\n",
        "    print(\"Predictions:\")\n",
        "\n",
        "    for word, prob in predictions:\n",
        "        print(f\"  {word}  (P={prob})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtZY8C5aMYSk",
        "outputId": "860b96f4-6115-4637-984f-7720919e0ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter text (or 'exit'): natural language\n",
            "\n",
            "Using Trigram Model\n",
            "Predictions:\n",
            "  processing  (P=1.0)\n",
            "\n",
            "Enter text (or 'exit'): natural language\n",
            "\n",
            "Using Trigram Model\n",
            "Predictions:\n",
            "  processing  (P=1.0)\n",
            "\n",
            "Enter text (or 'exit'): hello\n",
            "\n",
            "Using Unigram Model\n",
            "Predictions:\n",
            "  language  (P=0.08)\n",
            "  models  (P=0.06)\n",
            "  and  (P=0.04)\n",
            "  are  (P=0.04)\n",
            "  in  (P=0.04)\n"
          ]
        }
      ]
    }
  ]
}